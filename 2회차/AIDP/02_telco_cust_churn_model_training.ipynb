{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfd230f-2a60-4e3d-8202-cc1368553e74",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 0. 실버 Silver 레이어의 개념\n",
    "\n",
    "Oracle AI Data Platform의 메달리온 구조에서 실버 레이어는 브론즈에 저장된 원본 데이터를 분석과 모델링에 사용할 수 있도록 정제하는 단계입니다.\n",
    "\n",
    "브론즈 데이터는 원본 보관 목적이기 때문에 컬럼이 많고 문자열 표현이 제각각이며 결측치나 이상값이 포함될 수 있습니다.  \n",
    "실버 레이어에서는 이러한 데이터를 깨끗하고 일관된 구조로 다듬어 바로 모델 학습에 사용할 수 있도록 준비합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 실버 레이어의 핵심 목적\n",
    "\n",
    "- 브론즈 데이터를 실제 분석이나 머신러닝에 적합한 형태로 변환  \n",
    "- 범주형 컬럼을 숫자 기반 표현으로 변환  \n",
    "- 불필요한 컬럼 제거  \n",
    "- 데이터 품질을 확보하여 이후 골드 단계에서 바로 예측에 활용할 수 있는 기반 마련  \n",
    "\n",
    "---\n",
    "\n",
    "## 브론즈 → 실버 단계가 필요한 이유\n",
    "\n",
    "| 브론즈 데이터 문제점            | 실버 단계에서의 처리 방향                   |\n",
    "| ------------------------------ | ------------------------------------------- |\n",
    "| 값 표현이 제각각이고 통일되지 않음 | 문자열 정리와 일관된 값으로 변환              |\n",
    "| 범주형 문자열이 많아 모델이 처리 불가 | 인덱싱, 원핫 인코딩 등 숫자형 표현으로 변환     |\n",
    "| 결측치나 이상값이 일부 존재         | 필터링 또는 대체 처리로 모델 안정성 확보        |\n",
    "| 컬럼이 너무 많거나 불필요한 정보 포함 | 모델에 필요한 컬럼만 선택해 데이터 구조 단순화 |\n",
    "\n",
    "실버 레이어는 분석과 모델링을 위한 표준 데이터셋을 만드는 단계이며 골드 레이어에서 예측 결과를 생성하기 위한 핵심 기반이 됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 0-1. 이 노트북에서 수행하는 전체 흐름\n",
    "\n",
    "이 노트북은 실버 레이어 데이터를 기반으로 고객 이탈 예측 모델을 학습하는 전체 과정을 포함합니다.\n",
    "\n",
    "1. 실버 카탈로그에서 정제된 Telco 고객 데이터를 불러오기  \n",
    "2. 범주형 컬럼 인덱싱과 원핫 인코딩 적용  \n",
    "3. 수치형 컬럼과 함께 Feature Vector 생성  \n",
    "4. 로지스틱 회귀 모델 구성  \n",
    "5. Spark ML Pipeline으로 전체 학습 과정 묶기  \n",
    "6. 데이터를 학습용과 테스트용으로 분리  \n",
    "7. 모델 학습 수행  \n",
    "8. 테스트 데이터로 ROC AUC 평가  \n",
    "9. 모델 저장 및 재사용  \n",
    "\n",
    "이 과정을 통해 실버 데이터를 기반으로 완전한 머신러닝 학습 파이프라인을 구축하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ae41e-705d-467f-a4cf-fe66b42df2a2",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 1. 실습 파라미터 정의\n",
    "\n",
    "실버 레이어의 카탈로그/스키마 정보를 설정합니다.\n",
    "워크플로우에서 실행할 경우, 파라미터로도 받을 수 있도록 구성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b629e25b-f24c-407c-ad33-e20c4ad9954b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:01:22.729Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Catalog / Schema / Table 설정\n",
    "silver_catalog = \"demo_telco_churn_silver\"\n",
    "silver_schema  = \"telco_churn_historical\"\n",
    "silver_table   = \"telco_custchurn_history_par\"   # SHOW TABLES에서 확인한 실제 테이블 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28522652-8ae2-4ae3-bc84-8d468ddc6442",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 2. 라이브러리 import & Spark 세션 생성\n",
    "\n",
    "이 노트북은 PySpark 기반으로 실행됩니다.\n",
    "Spark 세션을 생성하면 실습 준비가 끝납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fd026c-a04f-4403-a755-d594f42d800a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:01:27.554Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"CustomerChurn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce02b0-49db-48eb-993c-5c572d06599a",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 3. Silver 카탈로그에서 Telco Churn 데이터 로드\n",
    "\n",
    "Bronze → Silver 레이어로 ETL이 끝난 정제된 데이터를 불러옵니다.\n",
    "- 실버 데이터는 스키마가 잘 정리되어 있고 사용할 수 있는 상태입니다.\n",
    "- 불필요한 컬럼(year)은 제거합니다.\n",
    "- 로딩 후 스키마 구조를 출력해 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02af645-e437-47cd-bef9-b62436ccd057",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:01:42.861Z"
    },
    "type": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root\n",
       " |-- customerid: string (nullable = true)\n",
       " |-- gender: string (nullable = true)\n",
       " |-- seniorcitizen: integer (nullable = true)\n",
       " |-- partner: string (nullable = true)\n",
       " |-- dependents: string (nullable = true)\n",
       " |-- tenure: integer (nullable = true)\n",
       " |-- phoneservice: string (nullable = true)\n",
       " |-- multiplelines: string (nullable = true)\n",
       " |-- internetservice: string (nullable = true)\n",
       " |-- onlinesecurity: string (nullable = true)\n",
       " |-- onlinebackup: string (nullable = true)\n",
       " |-- deviceprotection: string (nullable = true)\n",
       " |-- techsupport: string (nullable = true)\n",
       " |-- streamingtv: string (nullable = true)\n",
       " |-- streamingmovies: string (nullable = true)\n",
       " |-- contract: string (nullable = true)\n",
       " |-- paperlessbilling: string (nullable = true)\n",
       " |-- paymentmethod: string (nullable = true)\n",
       " |-- monthlycharges: double (nullable = true)\n",
       " |-- totalcharges: double (nullable = true)\n",
       " |-- churn: string (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read Customer Churn History data from Silver Catalog\n",
    "data = spark.read.table(f\"{silver_catalog}.{silver_schema}.{silver_table}\")\n",
    "\n",
    "# Remove 'year' column (not used in model training)\n",
    "data = data.drop(\"year\")\n",
    "\n",
    "# Inspect schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54d7b6-45d5-4b45-9f1f-10be231eee43",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 4. 데이터 전처리\n",
    "\n",
    "### 실습 목표\n",
    "- 범주형(categorical) 컬럼 변환\n",
    "- 수치형(numeric) 컬럼 확인\n",
    "- 머신러닝 모델이 학습할 수 있도록 피처 엔지니어링 수행\n",
    "\n",
    "## 4-1. 범주형 컬럼 변환\n",
    "\n",
    "Spark ML에서는 범주형 컬럼을 그대로 사용할 수 없기 때문에 StringIndexer → OneHotEncoder 과정을 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec4cb9e-159d-4b5d-8f93-dba57d7075f2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:01:50.573Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Process categorical and numeric attributes.\n",
    "# Identify categorical columns (exclude numeric ones)\n",
    "categoricalCols = [c for c in data.columns if data.schema[c].dataType == \"string\"]\n",
    "\n",
    "# String Indexing\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"_IDX\")\n",
    "    for col in categoricalCols\n",
    "]\n",
    "\n",
    "# OneHot Encoding\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCols=[col + \"_IDX\"], outputCols=[col + \"_OHE\"])\n",
    "    for col in categoricalCols\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a90ec-0247-4cf4-b3dc-2592aebef91e",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 4-2. Feature Vector 생성\n",
    "\n",
    "모든 피처를 하나의 벡터로 합쳐야 Spark ML이 처리할 수 있습니다.\n",
    "VectorAssembler가 그 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efce941e-e42a-4112-b835-1bed1df9bdaf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:01:56.067Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Assemble features into a single vector\n",
    "assemblerInputs = [col + \"_OHE\" for col in categoricalCols] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "# Index target label\n",
    "labelIndexer = StringIndexer(inputCol=\"churn\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a09d5-8f17-47f1-ae60-f52b1a16cdc4",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 5. 모델 학습\n",
    "\n",
    "Telco Churn 예측에서는 로지스틱 회귀(LogisticRegression)를 사용합니다.\n",
    "- 이진 분류-binary classification에 적합\n",
    "- 빠르고 실무에서 매우 많이 사용하는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818c4440-eee8-42a8-9c54-590e1430e73c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:02:01.947Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Train the ML Model\n",
    "# Logistic Regression Model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fef078-640f-4bd5-a34a-b99aff00faf0",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 6. ML 파이프라인 구성\n",
    "\n",
    "Spark ML의 강력한 기능인 Pipeline을 사용하여 전처리 → 인코딩 → 피처 생성 → 모델 흐름을 하나의 파이프라인으로 묶습니다.\n",
    "실무에서는 파이프라인객체를 모델 저장/배포에 그대로 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa892cfe-e6a3-49b3-ae3c-9155fddce8c3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:02:07.753Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=indexers + encoders + [assembler, labelIndexer, lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ebf93-e906-43e2-812e-46424e58f65a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T03:56:43.063Z"
    },
    "type": "markdown"
   },
   "source": [
    "## 7. 모델 학습 실행\n",
    "\n",
    "이제 데이터에 대해 전체 파이프라인을 fit합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f18895-a20e-40b0-abf2-6bbd8d78b3c0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:02:32.444Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Clean data (remove missing or invalid TotalCharges)\n",
    "data = data.filter(col(\"TotalCharges\").isNotNull())\n",
    "\n",
    "# Split data\n",
    "train, test = data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Fit model\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac10fa-cf19-4523-9cb0-fa40da7a45c7",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# 8. 모델 평가(Evaluation)\n",
    "\n",
    "모델이 학습된 후에는 테스트 데이터에 대해 예측을 수행하고, 예측 결과가 실제 레이블을 얼마나 잘 맞추는지 평가해야 합니다.\n",
    "\n",
    "여기서는 분류 모델에서 가장 널리 사용하는 평가 지표인 **ROC-AUC(Area&nbsp;Under&nbsp;ROC&nbsp;Curve)** 를 활용합니다.\n",
    "\n",
    "- ROC-AUC 값이 1에 가까울수록 모델이 우수함  \n",
    "- 0.5 수준이면 랜덤 추측과 동일  \n",
    "- Telco Churn 같은 고객 이탈 예측에서는 매우 중요한 지표\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a42eca-0719-43fe-a5ed-3d4813441b15",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:04:36.423Z"
    },
    "type": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test ROC-AUC = 0.803\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터에 대해 모델 예측 수행\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Binary Classification Evaluator 생성\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "# ROC-AUC 계산\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Test ROC-AUC = {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f91f0c-f1ec-480d-b18c-9594cb9e6a9b",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "모델이 테스트 데이터에 대해 계산한 예측 결과를 직접 확인해보는 단계입니다. \n",
    "이 과정은 모델이 예측을 어떻게 내리고 있는지, 그리고 확률 값이 어떻게 분포하는지 직관적으로 이해하는 데 도움이 됩니다.\n",
    "\n",
    "Spark의 예측 결과 DataFrame predictions 에는 다음과 같은 주요 컬럼이 포함됩니다:\n",
    "\n",
    "- Churn: 실제 고객 이탈 여부. 예: 0은 잔존, 1은 이탈\n",
    "- prediction: 모델이 예측한 이탈 여부. 예: 0 또는 1\n",
    "- probability: 모델이 계산한 이탈 확률. 예: [0.78, 0.22]\n",
    "\n",
    "아래 코드는 이 세 가지 컬럼만 선택해서 예측 샘플을 10개 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cc477e-858c-4707-a8cf-883e1f1da3be",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:10:40.157Z"
    },
    "type": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----+----------+-----------------------------------------+\n",
       "|Churn|prediction|probability                              |\n",
       "+-----+----------+-----------------------------------------+\n",
       "|No   |0.0       |[0.5955903579216851,0.40440964207831487] |\n",
       "|No   |0.0       |[0.8122339992369273,0.1877660007630727]  |\n",
       "|No   |0.0       |[0.9201335229637126,0.07986647703628735] |\n",
       "|No   |0.0       |[0.9708539492458342,0.029146050754165764]|\n",
       "|No   |0.0       |[0.9280859396468588,0.07191406035314118] |\n",
       "|No   |0.0       |[0.8580050730666826,0.1419949269333174]  |\n",
       "|No   |1.0       |[0.28014028459322393,0.7198597154067761] |\n",
       "|No   |0.0       |[0.9685509803225579,0.03144901967744207] |\n",
       "|No   |0.0       |[0.7577966071818952,0.24220339281810477] |\n",
       "|Yes  |0.0       |[0.6732906407854523,0.3267093592145477]  |\n",
       "+-----+----------+-----------------------------------------+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample predictions\n",
    "predictions.select(\"Churn\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314559b-9490-4f4b-858c-e7fd02d54cce",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 9. 모델 저장 단계\n",
    "\n",
    "모델 학습이 완료되면, 이후 재학습 없이 바로 예측에 활용하거나 다른 노트북에서 불러오기 위해 모델을 저장할 수 있습니다.  \n",
    "\n",
    "Spark의 PipelineModel 저장 기능을 사용하면 전체 전처리 과정과 모델이 하나의 객체로 저장됩니다.  \n",
    "이 방식은 운영 환경에서 안정적으로 재사용할 수 있다는 장점이 있습니다.  \n",
    "\n",
    "아래 코드는 학습된 모델을 지정된 경로에 저장하는 예입니다.  \n",
    "기존 동일 경로에 모델이 있을 경우에는 overwrite 옵션으로 덮어쓰기 방식으로 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242146ba-2f29-4bd6-a72e-44ed28ec806e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:17:34.107Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "#Save Model\n",
    "model.write().overwrite().save(\"/Workspace/demo_telco_churn_bronze_to_silver/telco_customer_churn_ml_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6ec31-5ea3-4c20-a7dc-7c69c3765cba",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "## 10. 저장된 모델 불러오기 단계\n",
    "\n",
    "학습이 완료된 모델은 지정된 경로에 저장되어 있으며, 다른 노트북이나 후속 처리 단계에서 재사용할 수 있습니다.  \n",
    "Spark의 PipelineModel.load 기능을 사용하면 저장된 모델을 그대로 메모리에 불러올 수 있습니다.\n",
    "\n",
    "아래 코드는 앞서 저장한 모델을 동일한 Workspace 경로에서 읽어오는 예입니다.  \n",
    "로드된 모델은 학습 당시의 전처리 과정과 파이프라인 구성을 그대로 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a669855f-31e7-48ae-a71d-87490e0d9daa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-04T04:18:51.026Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "loaded_model = PipelineModel.load(\"/Workspace/demo_telco_churn_bronze_to_silver/telco_customer_churn_ml_model\")"
   ]
  }
 ],
 "metadata": {
  "Last_Active_Cell_Index": 1,
  "kernelspec": {
   "name": "notebook"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
